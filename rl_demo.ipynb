{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# RL Agent Training Demo\\n\",\n",
    "    \"This notebook demonstrates training a LinUCB contextual bandit agent on a small subset of data.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"from core.features import FeaturePipeline\\n\",\n",
    "    \"from core.models.rl_agent import LinUCBAgent, RLTrainer\\n\",\n",
    "    \"\\n\",\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"plt.style.use('ggplot')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 1: Load Feature Store\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"pipeline = FeaturePipeline()\\n\",\n",
    "    \"feature_dict = pipeline.load_feature_store()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Loaded features for {len(feature_dict)} symbols\\\")\\n\",\n",
    "    \"print(\\\"Symbols:\\\", list(feature_dict.keys())[:10])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 2: Extract Feature Dimensions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Get feature columns from first symbol\\n\",\n",
    "    \"sample_df = next(iter(feature_dict.values()))\\n\",\n",
    "    \"exclude_cols = ['open', 'high', 'low', 'close', 'volume', 'adj_close',\\n\",\n",
    "    \"                'symbol', 'source', 'fetch_timestamp',\\n\",\n",
    "    \"                'target', 'target_return', 'target_direction', 'target_binary']\\n\",\n",
    "    \"feature_cols = [c for c in sample_df.columns if c not in exclude_cols]\\n\",\n",
    "    \"n_features = len(feature_cols)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Number of features: {n_features}\\\")\\n\",\n",
    "    \"print(f\\\"Feature examples: {feature_cols[:10]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 3: Initialize LinUCB Agent\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Create agent\\n\",\n",
    "    \"agent = LinUCBAgent(n_features=n_features, alpha=1.0)\\n\",\n",
    "    \"print(f\\\"LinUCB agent initialized with {agent.n_features} features\\\")\\n\",\n",
    "    \"print(f\\\"Exploration parameter (alpha): {agent.alpha}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 4: Training Loop (Simplified Demo)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Take a small subset for quick demo\\n\",\n",
    "    \"demo_symbols = list(feature_dict.keys())[:5]\\n\",\n",
    "    \"demo_feature_dict = {sym: feature_dict[sym] for sym in demo_symbols}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training on {len(demo_feature_dict)} symbols: {demo_symbols}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Initialize trainer\\n\",\n",
    "    \"trainer = RLTrainer(\\n\",\n",
    "    \"    agent=agent,\\n\",\n",
    "    \"    feature_store=demo_feature_dict,\\n\",\n",
    "    \"    agent_type='linucb'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train for 20 rounds (quick demo)\\n\",\n",
    "    \"print(\\\"\\\\nTraining agent...\\\")\\n\",\n",
    "    \"stats = trainer.train_bandit(n_rounds=20, top_k=3, horizon=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTraining complete!\\\")\\n\",\n",
    "    \"print(f\\\"Average reward: {stats['avg_reward']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Cumulative reward: {stats['cumulative_reward']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 5: Visualize Training Progress\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Plot rewards over training rounds\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(stats['rewards_per_round'])\\n\",\n",
    "    \"plt.title('Reward per Round')\\n\",\n",
    "    \"plt.xlabel('Round')\\n\",\n",
    "    \"plt.ylabel('Reward')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"cumulative = np.cumsum(stats['rewards_per_round'])\\n\",\n",
    "    \"plt.plot(cumulative)\\n\",\n",
    "    \"plt.title('Cumulative Reward')\\n\",\n",
    "    \"plt.xlabel('Round')\\n\",\n",
    "    \"plt.ylabel('Cumulative Reward')\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 6: Test Ranking\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Prepare contexts for ranking\\n\",\n",
    "    \"contexts = {}\\n\",\n",
    "    \"for symbol, df in demo_feature_dict.items():\\n\",\n",
    "    \"    if not df.empty:\\n\",\n",
    "    \"        context = df[feature_cols].iloc[-1].values\\n\",\n",
    "    \"        context = np.nan_to_num(context, nan=0.0, posinf=0.0, neginf=0.0)\\n\",\n",
    "    \"        contexts[symbol] = context\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Rank symbols\\n\",\n",
    "    \"rankings = agent.rank_symbols(contexts, top_k=None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nSymbol Rankings:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"for i, (symbol, score, confidence) in enumerate(rankings, 1):\\n\",\n",
    "    \"    print(f\\\"{i}. {symbol:10s} - Score: {score:8.4f} - Confidence: {confidence:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 7: Understanding the Agent\\n\",\n",
    "    \"\\n\",\n",
    "    \"### LinUCB Algorithm\\n\",\n",
    "    \"LinUCB (Linear Upper Confidence Bound) is a contextual bandit algorithm that:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Maintains a linear model** for each symbol (arm)\\n\",\n",
    "    \"2. **Balances exploration vs exploitation** using UCB formula:\\n\",\n",
    "    \"   ```\\n\",\n",
    "    \"   score = θᵀx + α√(xᵀA⁻¹x)\\n\",\n",
    "    \"   ```\\n\",\n",
    "    \"   - First term: expected reward (exploitation)\\n\",\n",
    "    \"   - Second term: uncertainty bonus (exploration)\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Updates parameters** after observing rewards:\\n\",\n",
    "    \"   - `A = A + xxᵀ` (feature covariance)\\n\",\n",
    "    \"   - `b = b + rx` (feature-reward product)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Reward Design\\n\",\n",
    "    \"In this demo, reward = future return × 100\\n\",\n",
    "    \"- Positive returns → positive rewards\\n\",\n",
    "    \"- Negative returns → negative rewards\\n\",\n",
    "    \"- Agent learns to rank symbols with higher expected returns\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Why LinUCB for Ranking?\\n\",\n",
    "    \"- Fast computation (matrix operations)\\n\",\n",
    "    \"- Provides confidence estimates\\n\",\n",
    "    \"- Works well with high-dimensional features\\n\",\n",
    "    \"- No need for neural networks\\n\",\n",
    "    \"- Perfect for edge deployment\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 8: Evaluation Metrics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Evaluate agent\\n\",\n",
    "    \"eval_metrics = trainer.evaluate(top_k=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nEvaluation Metrics:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"print(f\\\"Mean Return: {eval_metrics['mean_return']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Sharpe Proxy: {eval_metrics['sharpe_proxy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Win Rate: {eval_metrics['win_rate']:.2%}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nTop Symbols: {eval_metrics['top_symbols']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrated:\\n\",\n",
    "    \"1. Loading feature store\\n\",\n",
    "    \"2. Initializing LinUCB agent\\n\",\n",
    "    \"3. Training on small subset (20 rounds)\\n\",\n",
    "    \"4. Visualizing training progress\\n\",\n",
    "    \"5. Ranking symbols by UCB scores\\n\",\n",
    "    \"6. Evaluating agent performance\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Takeaways:\\n\",\n",
    "    \"- LinUCB balances trying new symbols (exploration) vs selecting known good ones (exploitation)\\n\",\n",
    "    \"- The agent learns from rewards (future returns)\\n\",\n",
    "    \"- Confidence scores help us understand prediction uncertainty\\n\",\n",
    "    \"- This lightweight approach works well for edge deployment\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"- Train on full dataset with more rounds\\n\",\n",
    "    \"- Try Thompson Sampling or DQN agents\\n\",\n",
    "    \"- Tune hyperparameters (alpha for exploration)\\n\",\n",
    "    \"- Add portfolio-level evaluation\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
